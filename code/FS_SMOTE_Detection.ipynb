{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb93354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc, average_precision_score,)\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load dataset\n",
    "data = pd.read_csv(\"results/cicids2017_cleaned_numericable.csv\")\n",
    "masv_df = pd.read_csv(\"results/xgbmasv.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7af080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change infinity and NaN with median\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.fillna(data.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e3f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split feature and label\n",
    "X = data.drop(columns=['Label']).values  # Fitur\n",
    "y = data['Label'].values  # Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88acdd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize MASV\n",
    "masv_values = masv_df['masv'].values  # Retrieve MASV values\n",
    "masv_normalized = (masv_values - np.min(masv_values)) / (np.max(masv_values) - np.min(masv_values))\n",
    "\n",
    "# Ensure the normalization index matches the feature names in `masv_df`\n",
    "masv_series = pd.Series(masv_normalized, index=masv_df['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4618b78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dengan MASV Normalized telah disimpan ke file Excel: XGBmasv_normalized_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Add the normalized column to the DataFrame\n",
    "masv_df['masv_normalized'] = masv_normalized\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "output_file = \"results/xgbmasv_normalized.xlsx\"\n",
    "masv_df.to_excel(output_file, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Data with normalized MASV has been saved to the Excel file: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60931998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806cac42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features based on top 20% MASV:\n",
      "['Destination Port', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'Bwd Packets/s', 'min_seg_size_forward', 'Packet Length Mean', 'Flow IAT Min', 'Fwd IAT Min', 'Flow Bytes/s', 'Total Length of Fwd Packets', 'Bwd Packet Length Std', 'Average Packet Size', 'Flow IAT Max', 'Bwd Packet Length Mean', 'Fwd Header Length']\n",
      "\n",
      "⏱️ Waktu proses seleksi fitur: 0.0157 detik\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Feature selection based on MASV\n",
    "def select_top_features(X, masv_df, percentile=20):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Sort MASV values and select the top features based on the given percentile\n",
    "    masv_df_sorted = masv_df.sort_values(by='masv', ascending=False)\n",
    "    num_features_to_select = int(len(masv_df) * (percentile / 100))\n",
    "    selected_features = masv_df_sorted['feature'].head(num_features_to_select).values\n",
    "    \n",
    "    print(f\"Selected features based on top {percentile}% MASV:\")\n",
    "    print(list(selected_features))\n",
    "    \n",
    "    # Ensure X is a DataFrame. If not, convert it and assign column names according to masv_df\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X_df = pd.DataFrame(X, columns=masv_df['feature'])\n",
    "    else:\n",
    "        X_df = X\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    print(f\"\\n⏱️ Feature selection process time: {duration:.4f} seconds\")\n",
    "    \n",
    "    # Return the selected feature data and list of selected feature names\n",
    "    return X_df[selected_features], list(selected_features)\n",
    "\n",
    "# Step 5: Apply feature selection\n",
    "if isinstance(X_train, np.ndarray):\n",
    "    X_train = pd.DataFrame(X_train, columns=masv_df['feature'])\n",
    "\n",
    "X_train_selected, selected_features = select_top_features(X_train, masv_df, percentile=20)\n",
    "\n",
    "# If `X_test` is a NumPy array, convert it to a DataFrame\n",
    "if isinstance(X_test, np.ndarray):\n",
    "    X_test = pd.DataFrame(X_test, columns=masv_df['feature'])\n",
    "\n",
    "# Apply the same feature selection to `X_test`\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Get the integer indices of the selected features\n",
    "selected_indices = [X_train.columns.get_loc(feature) for feature in selected_features]\n",
    "\n",
    "# Use the integer indices to select the corresponding MASV weights\n",
    "masv_weights_selected = masv_normalized[selected_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e407c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi data sebelum balancing (training set):\n",
      "Kelas 0: 795246 sampel\n",
      "Kelas 1: 692 sampel\n",
      "Kelas 2: 4797 sampel\n",
      "Kelas 3: 132776 sampel\n",
      "Kelas 4: 13 sampel\n",
      "Kelas 5: 55495 sampel\n",
      "Kelas 6: 745 sampel\n",
      "\n",
      "⏱️ Waktu proses MASV-weighted SMOTE: 8.80 detik\n",
      "\n",
      "Distribusi data setelah balancing:\n",
      "Kelas 0: 795246 sampel\n",
      "Kelas 1: 10000 sampel\n",
      "Kelas 2: 10000 sampel\n",
      "Kelas 3: 132776 sampel\n",
      "Kelas 4: 10000 sampel\n",
      "Kelas 5: 55495 sampel\n",
      "Kelas 6: 10000 sampel\n"
     ]
    }
   ],
   "source": [
    "# 4. Function for Weighted SMOTE with Minority Class Adjustment\n",
    "def weighted_smote_multiclass(X, y, masv_weights, k_neighbors=1, target_sample_size=10000):\n",
    "    \"\"\"\n",
    "    Weighted SMOTE for multiclass datasets based on MASV values.\n",
    "    \n",
    "    Parameters:\n",
    "    X: Original feature data\n",
    "    y: Class labels\n",
    "    masv_weights: Feature weights derived from MASV values\n",
    "    k_neighbors: Number of nearest neighbors for interpolation\n",
    "    target_sample_size: Desired total number of samples for each class\n",
    "    \n",
    "    Returns:\n",
    "    X_resampled: Feature data after SMOTE\n",
    "    y_resampled: Label data after SMOTE\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Start timer\n",
    "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "    X_synthetic = []\n",
    "    y_synthetic = []\n",
    "    \n",
    "    for class_label, class_count in zip(unique_classes, class_counts):\n",
    "        # Calculate how many samples need to be generated for this class\n",
    "        n_samples_to_generate = target_sample_size - class_count\n",
    "        if n_samples_to_generate <= 0:\n",
    "            continue  # Skip if the class already meets the target\n",
    "\n",
    "        # Extract data for the current class\n",
    "        X_class = X[y == class_label]\n",
    "\n",
    "        # Define nearest neighbors for interpolation\n",
    "        neigh = NearestNeighbors(n_neighbors=k_neighbors)\n",
    "        neigh.fit(X_class)\n",
    "\n",
    "        for i in range(n_samples_to_generate):\n",
    "            # Randomly select a minority sample and find its nearest neighbor\n",
    "            index = np.random.randint(0, len(X_class))\n",
    "            x_sample = X_class[index]\n",
    "            neighbors = neigh.kneighbors([x_sample], return_distance=False)\n",
    "            neighbor_index = np.random.choice(neighbors[0])\n",
    "            x_neighbor = X_class[neighbor_index]\n",
    "\n",
    "            # Weighted interpolation\n",
    "            lambda_ = np.random.random()\n",
    "            x_synthetic = x_sample + lambda_ * (x_neighbor - x_sample) * masv_weights\n",
    "            X_synthetic.append(x_synthetic)\n",
    "            y_synthetic.append(class_label)\n",
    "\n",
    "    if len(X_synthetic) == 0:\n",
    "        print(\"No synthetic samples were generated.\")\n",
    "        return X, y\n",
    "\n",
    "    # Combine original and synthetic data\n",
    "    X_resampled = np.vstack([X, np.array(X_synthetic)])\n",
    "    y_resampled = np.hstack([y, np.array(y_synthetic)])\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    print(f\"\\n⏱️ MASV-weighted SMOTE process time: {duration:.2f} seconds\")\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "# Display class distribution before balancing\n",
    "print(\"Class distribution before balancing (training set):\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_distribution_before = dict(zip(unique, counts))\n",
    "for label, count in class_distribution_before.items():\n",
    "    print(f\"Class {label}: {count} samples\")\n",
    "\n",
    "# Execute multiclass SMOTE\n",
    "X_train_balanced, y_train_balanced = weighted_smote_multiclass(\n",
    "    X_train_selected.values,\n",
    "    y_train,\n",
    "    masv_weights_selected,\n",
    "    k_neighbors=1,\n",
    "    target_sample_size=10000\n",
    ")\n",
    "\n",
    "# Display class distribution after balancing\n",
    "print(\"\\nClass distribution after balancing:\")\n",
    "unique_balanced, counts_balanced = np.unique(y_train_balanced, return_counts=True)\n",
    "class_distribution_after = dict(zip(unique_balanced, counts_balanced))\n",
    "for label, count in class_distribution_after.items():\n",
    "    print(f\"Class {label}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7810d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluasi Model Sebelum Balancing:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluasi Kinerja Model:\n",
      "Akurasi: 0.9992\n",
      "Precision (weighted): 0.9991\n",
      "Recall (weighted): 0.9992\n",
      "F1-score (weighted): 0.9991\n",
      "Confusion Matrix:\n",
      " [[340180     16      0     62      0    162      0]\n",
      " [    63    221      0      0      0      0      0]\n",
      " [     1      0   2117      0      0      0      0]\n",
      " [    27      0      0  57069      0      3      0]\n",
      " [     5      0      0      0      0      0      0]\n",
      " [     3      0      0      3      0  23907      1]\n",
      " [     8      0      1      1      0      0    335]]\n",
      "\n",
      "PR-AUC (Micro-Averaged): 1.0000\n",
      "\n",
      "PR-AUC per kelas:\n",
      "  Kelas 0: 1.0000\n",
      "  Kelas 1: 0.9517\n",
      "  Kelas 2: 1.0000\n",
      "  Kelas 3: 1.0000\n",
      "  Kelas 4: 0.2136\n",
      "  Kelas 5: 0.9990\n",
      "  Kelas 6: 0.9942\n",
      "\n",
      "\n",
      "Waktu Eksekusi:\n",
      "  Waktu Pelatihan: 19.44 detik\n",
      "  Waktu Prediksi: 1.72 detik\n",
      "\n",
      "\n",
      "Evaluasi Model Setelah Balancing:\n",
      "\n",
      "Evaluasi Kinerja Model:\n",
      "Akurasi: 0.9991\n",
      "Precision (weighted): 0.9992\n",
      "Recall (weighted): 0.9991\n",
      "F1-score (weighted): 0.9991\n",
      "Confusion Matrix:\n",
      " [[340078    117      0     63      0    162      0]\n",
      " [     2    282      0      0      0      0      0]\n",
      " [     1      0   2117      0      0      0      0]\n",
      " [    23      0      0  57073      0      3      0]\n",
      " [     4      0      0      0      1      0      0]\n",
      " [     3      0      0      3      0  23906      2]\n",
      " [     7      0      0      1      0      0    337]]\n",
      "\n",
      "PR-AUC (Micro-Averaged): 1.0000\n",
      "\n",
      "PR-AUC per kelas:\n",
      "  Kelas 0: 1.0000\n",
      "  Kelas 1: 0.9515\n",
      "  Kelas 2: 1.0000\n",
      "  Kelas 3: 1.0000\n",
      "  Kelas 4: 1.0000\n",
      "  Kelas 5: 0.9990\n",
      "  Kelas 6: 0.9976\n",
      "\n",
      "\n",
      "Waktu Eksekusi:\n",
      "  Waktu Pelatihan: 22.13 detik\n",
      "  Waktu Prediksi: 1.46 detik\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Modeling and Evaluation\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, num_classes):\n",
    "    \"\"\"\n",
    "    Train and evaluate an XGBoost model for multiclass classification with global (micro-averaged) PR-AUC.\n",
    "    \"\"\"\n",
    "    # Create the XGBoost model\n",
    "    model = XGBClassifier(\n",
    "        objective='multi:softprob',   # For multiclass classification\n",
    "        num_class=num_classes,        # Number of classes\n",
    "        eval_metric='mlogloss',       # Evaluation metric: log-loss\n",
    "        use_label_encoder=False,      # Avoid XGBoost warning\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    start_train_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_train_time = time.time()\n",
    "    train_duration = end_train_time - start_train_time\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    start_predict_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    end_predict_time = time.time()\n",
    "    predict_duration = end_predict_time - start_predict_time\n",
    "    \n",
    "    # Compute general performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # One-hot encode y_test for PR-AUC computation\n",
    "    y_test_one_hot = np.zeros((y_test.size, num_classes))\n",
    "    y_test_one_hot[np.arange(y_test.size), y_test] = 1\n",
    "\n",
    "    # Precision-Recall curve for micro-averaged PR-AUC\n",
    "    precision_micro, recall_micro, _ = precision_recall_curve(\n",
    "        y_test_one_hot.ravel(), y_pred_proba.ravel()\n",
    "    )\n",
    "    pr_auc_micro = auc(recall_micro, precision_micro)\n",
    "\n",
    "    # Compute PR-AUC per class for reference\n",
    "    pr_auc_per_class = []\n",
    "    for i in range(num_classes):\n",
    "        precision_class, recall_class, _ = precision_recall_curve(y_test_one_hot[:, i], y_pred_proba[:, i])\n",
    "        pr_auc_per_class.append(auc(recall_class, precision_class))\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(\"\\nModel Performance Evaluation:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision (weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (weighted): {recall:.4f}\")\n",
    "    print(f\"F1-score (weighted): {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    print(f\"\\nPR-AUC (Micro-Averaged): {pr_auc_micro:.4f}\")\n",
    "    print(\"\\nPR-AUC per Class:\")\n",
    "    for i, auc_val in enumerate(pr_auc_per_class):\n",
    "        print(f\"  Class {i}: {auc_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    # Print execution time\n",
    "    print(\"\\nExecution Time:\")\n",
    "    print(f\"  Training Time: {train_duration:.2f} seconds\")\n",
    "    print(f\"  Prediction Time: {predict_duration:.2f} seconds\")\n",
    "    print()\n",
    "    \n",
    "\n",
    "# Evaluate the model before and after balancing\n",
    "print(\"\\nModel Evaluation Before Balancing:\")\n",
    "evaluate_model(X_train_selected, y_train, X_test_selected, y_test, num_classes=len(np.unique(y_train)))\n",
    "\n",
    "print(\"\\nModel Evaluation After Balancing:\")\n",
    "evaluate_model(X_train_balanced, y_train_balanced, X_test_selected, y_test, num_classes=len(np.unique(y_train_balanced)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec142473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluasi Model Sebelum Balancing Per Kelas:\n",
      "\n",
      "Overall Accuracy: 0.9992\n",
      "\n",
      "Evaluasi Kinerja Model Per Kelas:\n",
      "\n",
      "Class 0:\n",
      "  Accuracy: 0.9992\n",
      "  Precision: 0.9997\n",
      "  Recall: 0.9993\n",
      "  F1-score: 0.9995\n",
      "  PR-AUC: 1.0000\n",
      "  FNR (False Negative Rate): 0.0007\n",
      "  FPR (False Positive Rate): 0.0012\n",
      "  Confusion Matrix:\n",
      "[[ 83665    100]\n",
      " [   236 340184]]\n",
      "\n",
      "Class 1:\n",
      "  Accuracy: 0.9998\n",
      "  Precision: 0.9109\n",
      "  Recall: 0.7923\n",
      "  F1-score: 0.8475\n",
      "  PR-AUC: 0.9509\n",
      "  FNR (False Negative Rate): 0.2077\n",
      "  FPR (False Positive Rate): 0.0001\n",
      "  Confusion Matrix:\n",
      "[[423879     22]\n",
      " [    59    225]]\n",
      "\n",
      "Class 2:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.9991\n",
      "  F1-score: 0.9995\n",
      "  PR-AUC: 1.0000\n",
      "  FNR (False Negative Rate): 0.0009\n",
      "  FPR (False Positive Rate): 0.0000\n",
      "  Confusion Matrix:\n",
      "[[422067      0]\n",
      " [     2   2116]]\n",
      "\n",
      "Class 3:\n",
      "  Accuracy: 0.9998\n",
      "  Precision: 0.9990\n",
      "  Recall: 0.9995\n",
      "  F1-score: 0.9993\n",
      "  PR-AUC: 1.0000\n",
      "  FNR (False Negative Rate): 0.0005\n",
      "  FPR (False Positive Rate): 0.0002\n",
      "  Confusion Matrix:\n",
      "[[367028     58]\n",
      " [    27  57072]]\n",
      "\n",
      "Class 4:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.2000\n",
      "  F1-score: 0.3333\n",
      "  PR-AUC: 0.3360\n",
      "  FNR (False Negative Rate): 0.8000\n",
      "  FPR (False Positive Rate): 0.0000\n",
      "  Confusion Matrix:\n",
      "[[424180      0]\n",
      " [     4      1]]\n",
      "\n",
      "Class 5:\n",
      "  Accuracy: 0.9996\n",
      "  Precision: 0.9931\n",
      "  Recall: 0.9997\n",
      "  F1-score: 0.9964\n",
      "  PR-AUC: 0.9990\n",
      "  FNR (False Negative Rate): 0.0003\n",
      "  FPR (False Positive Rate): 0.0004\n",
      "  Confusion Matrix:\n",
      "[[400106    165]\n",
      " [     8  23906]]\n",
      "\n",
      "Class 6:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 0.9940\n",
      "  Recall: 0.9681\n",
      "  F1-score: 0.9809\n",
      "  PR-AUC: 0.9942\n",
      "  FNR (False Negative Rate): 0.0319\n",
      "  FPR (False Positive Rate): 0.0000\n",
      "  Confusion Matrix:\n",
      "[[423838      2]\n",
      " [    11    334]]\n",
      "\n",
      "Evaluasi Model Setelah Balancing Per Kelas:\n",
      "\n",
      "Overall Accuracy: 0.9992\n",
      "\n",
      "Evaluasi Kinerja Model Per Kelas:\n",
      "\n",
      "Class 0:\n",
      "  Accuracy: 0.9992\n",
      "  Precision: 0.9999\n",
      "  Recall: 0.9991\n",
      "  F1-score: 0.9995\n",
      "  PR-AUC: 1.0000\n",
      "  FNR (False Negative Rate): 0.0009\n",
      "  FPR (False Positive Rate): 0.0005\n",
      "  Confusion Matrix:\n",
      "[[ 83721     44]\n",
      " [   308 340112]]\n",
      "\n",
      "Class 1:\n",
      "  Accuracy: 0.9998\n",
      "  Precision: 0.7392\n",
      "  Recall: 0.9683\n",
      "  F1-score: 0.8384\n",
      "  PR-AUC: 0.9520\n",
      "  FNR (False Negative Rate): 0.0317\n",
      "  FPR (False Positive Rate): 0.0002\n",
      "  Confusion Matrix:\n",
      "[[423804     97]\n",
      " [     9    275]]\n",
      "\n",
      "Class 2:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.9991\n",
      "  F1-score: 0.9995\n",
      "  PR-AUC: 1.0000\n",
      "  FNR (False Negative Rate): 0.0009\n",
      "  FPR (False Positive Rate): 0.0000\n",
      "  Confusion Matrix:\n",
      "[[422067      0]\n",
      " [     2   2116]]\n",
      "\n",
      "Class 3:\n",
      "  Accuracy: 0.9998\n",
      "  Precision: 0.9991\n",
      "  Recall: 0.9996\n",
      "  F1-score: 0.9993\n",
      "  PR-AUC: 1.0000\n",
      "  FNR (False Negative Rate): 0.0004\n",
      "  FPR (False Positive Rate): 0.0001\n",
      "  Confusion Matrix:\n",
      "[[367032     54]\n",
      " [    22  57077]]\n",
      "\n",
      "Class 4:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.6000\n",
      "  F1-score: 0.7500\n",
      "  PR-AUC: 0.9633\n",
      "  FNR (False Negative Rate): 0.4000\n",
      "  FPR (False Positive Rate): 0.0000\n",
      "  Confusion Matrix:\n",
      "[[424180      0]\n",
      " [     2      3]]\n",
      "\n",
      "Class 5:\n",
      "  Accuracy: 0.9996\n",
      "  Precision: 0.9932\n",
      "  Recall: 0.9997\n",
      "  F1-score: 0.9965\n",
      "  PR-AUC: 0.9990\n",
      "  FNR (False Negative Rate): 0.0003\n",
      "  FPR (False Positive Rate): 0.0004\n",
      "  Confusion Matrix:\n",
      "[[400108    163]\n",
      " [     7  23907]]\n",
      "\n",
      "Class 6:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 0.9941\n",
      "  Recall: 0.9710\n",
      "  F1-score: 0.9824\n",
      "  PR-AUC: 0.9973\n",
      "  FNR (False Negative Rate): 0.0290\n",
      "  FPR (False Positive Rate): 0.0000\n",
      "  Confusion Matrix:\n",
      "[[423838      2]\n",
      " [    10    335]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_per_class(X_train, y_train, X_test, y_test, class_labels):\n",
    "    \"\"\"\n",
    "    Evaluate a multiclass XGBoost model performance per class.\n",
    "    \"\"\"\n",
    "    # Train the XGBoost model\n",
    "    model = XGBClassifier(\n",
    "        objective=\"multi:softprob\",   # Multiclass probability output\n",
    "        num_class=len(class_labels),  # Number of classes\n",
    "        use_label_encoder=False,      # Avoid deprecation warning\n",
    "        eval_metric=\"mlogloss\",       # Default evaluation metric for multiclass\n",
    "        random_state=42,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)  # Probabilities for PR-AUC calculation\n",
    "\n",
    "    # Overall Accuracy\n",
    "    overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nOverall Accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "    print(\"\\nModel Performance Evaluation Per Class:\")\n",
    "\n",
    "    # Iterate through each class\n",
    "    for cls in class_labels:\n",
    "        # Binarize labels for the current class\n",
    "        y_test_binary = (y_test == cls).astype(int)\n",
    "        y_pred_binary = (y_pred == cls).astype(int)\n",
    "\n",
    "        # Accuracy per class\n",
    "        accuracy_class = accuracy_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "        # Precision, Recall, and F1-score\n",
    "        precision = precision_score(y_test_binary, y_pred_binary, zero_division=0)\n",
    "        recall = recall_score(y_test_binary, y_pred_binary, zero_division=0)\n",
    "        f1 = f1_score(y_test_binary, y_pred_binary, zero_division=0)\n",
    "\n",
    "        # Confusion Matrix for the current class\n",
    "        conf_matrix = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "        tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "        # False Positive Rate (FPR) and False Negative Rate (FNR)\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "        # Precision-Recall Curve and PR-AUC\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_test_binary, y_pred_proba[:, cls])\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "\n",
    "        # Print metrics for the current class\n",
    "        print(f\"\\nClass {cls}:\")\n",
    "        print(f\"  Accuracy: {accuracy_class:.4f}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1-score: {f1:.4f}\")\n",
    "        print(f\"  PR-AUC: {pr_auc:.4f}\")\n",
    "        print(f\"  FNR (False Negative Rate): {fnr:.4f}\")\n",
    "        print(f\"  FPR (False Positive Rate): {fpr:.4f}\")\n",
    "        print(f\"  Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "class_labels = sorted(np.unique(y_test))  # Ensure consistent order of class labels\n",
    "\n",
    "print(\"\\nModel Evaluation Before Balancing (Per Class):\")\n",
    "evaluate_model_per_class(X_train_selected, y_train, X_test_selected, y_test, class_labels)\n",
    "\n",
    "print(\"\\nModel Evaluation After Balancing (Per Class):\")\n",
    "evaluate_model_per_class(X_train_balanced, y_train_balanced, X_test_selected, y_test, class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf64f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
